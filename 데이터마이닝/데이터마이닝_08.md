# 8.신경망모형

### 예제 1 nnet
iris 자료에 대해 신경망 모형을 적합한다.  
자료의 수는 150개이며 입력변수의 차원은 4이며, 목표값은 3개의 범주로 출력된다.
```{r ex_1_1}
library(nnet)
nn.iris <- nnet(Species~., data=iris,
                size=2,      # 은닉층의 노드 수(size)는 2
                rang=0.1,    # 초기 랜덤 가중치의 범위는 [-0.1, 0.1]
                decay=5e-4,  # weight decay 모수는 0(디폴트)
                maxit=200)   # 최대반복수는 200(디폴트는 100)
summary(nn.iris)
```
위의 결과는 연결선의 방향과 가중치를 나타낸다.  
다만, 초깃값이 별도로 지정하지 않으면 nnet() 함수가 실행될 때 마다 결과가 달라질 것이다.  


  
적합결과를 시각화 하면 다음과 같다.  
시각화를 위한 plot.nnet() 함수는 아래의 절차에 따라 불러올 수 있다.  
```{r ex_1_2}
library(devtools)
source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')
plot.nnet(nn.iris)
```



```{r ex_1_3, warning=FALSE}
library(clusterGeneration)
library(scales)
library(reshape)
plot(nn.iris)
```
신경망 모형에 대한 정오분류표는 다음과 같다.  
```{r ex_1_4}
table(iris$Species, predict(nn.iris, iris, type = "class"))
```
분류된 데이터를 실제 값과 비교해보면  
setosa는 50개 모두 잘 분류 되었고,  
versicolor은 50개 중 49개가 잘 분류되었으며  
virginica는 50개중 49개가 잘 분류되었다.

### 예제2 neuralnet
자료 infert는 자연유산과 인공유산 후의 불임에 대한 사례-대조 연구 자료로 8개의 변수와 248개의 관측치를 가지고 있다.  
반응변수 case는 (1:사례, 0:대조)를 나타낸다.
```{r ex_2_1}
data(infert, package="datasets")
str(infert)
```



```{r ex_2_2, warning=FALSE}
library(neuralnet)
net.infert <- neuralnet(case~age+parity+induced+spontaneous,
                        data=infert, hidden=2, err.fct="ce",
                        linear.output=FALSE, likelihood=TRUE)
# hidden= 은닉층의 노드 수. err.fct= 오차(error) 계산에 사용되는 미분가능 함수로 “sse”, “ce”(cross entropy) 지정 가능
net.infert
```


neuralnet() 함수는 다양한 역전파 알고리즘을 통해 모형을 적합하며,  
수행 결과(객체)는 plot() 함수를 통해 다음과 같이 편리하게 시각화 된다.
```{r ex_2_3}
plot(net.infert)
```


neuralnet() 함수의 수행 결과의 추가적인 정보는 다음 과정을 통해 확인할 수 있다.
```{r ex_2_4}
names(net.infert)
```


이 가운데 결과 행렬에 대한 정보는 다음을 통해 확인할 수 있다.
```{r ex_2_5}
net.infert$result.matrix
```


원 자료와 함께 적합값을 출력하는 절차는 다음과 같다.  
전체자료는 $data에 저장되어 있고,  
모형 적합에 사용된 자료는 $covariate과 $response를 통해 확인 가능 하며,  
적합값은 $net.result에 제공된다.
```{r ex_2_6}
out <- cbind(net.infert$covariate, net.infert$net.result[[1]])
dimnames(out) <- list(NULL, c("age","parity","induced","spontaneous", "nn-output"))
head(out)
```



```{r ex_2_7}
head(net.infert$generalized.weights[[1]]) # 열은 4개의 입력변수
```

일반화가중치에 대한 시각화를 수행하면 다음과 같다.
```{r ex_2_8}
par(mfrow=c(2,2))
gwplot(net.infert, selected.covariate="age", min=-2.5, max=5)
gwplot(net.infert, selected.covariate="parity", min=-2.5, max=5)
gwplot(net.infert, selected.covariate="induced", min=-2.5, max=5)
gwplot(net.infert, selected.covariate="spontaneous", min=-2.5, max=5)
par(mfrow=c(1,1))
```



```{r ex_2_9}
new.output <- compute(net.infert, 
                      covariate=matrix(c(22,1,0,0,
                                         22,1,1,0,
                                         22,1,0,1,
                                         22,1,1,1),
                                       byrow=TRUE, ncol=4))
new.output$net.result
```
위의 결과(new.output$net.result)는 주어진 공변량 조합에 대한 예측 결과로,  
사전 낙태의 수에 따라 예측 확률이 증가함을 보여준다.

### 예제 3 neuralnet
0과 100 사이의 난수를 50개 발생시키고, 제곱근을 취한 값을 결과로 하는 자료를 구축한다.   
이 자료를 신경망으로 학습하여 새로운 자료에 대한 예측을 수행한다.  
set.seed() 함수를 이용하여 초깃값을 지정한 후 아래의 절차를 수행하면 일정한 결과를 얻을 수 있다.
```{r ex_3_1}
library(neuralnet)
train.input <- as.data.frame(runif(50, min=0, max=100))
train.output <- sqrt(train.input)
train.data <- cbind(train.input, train.output)
colnames(train.data) <- c("Input","Output")
head(train.data)
```


1개의 은닉층과 10개의 은닉노드를 가지는 신경망모형을 적합한다.  
threshold= 옵션은 오차 함수의 편미분에 대한 값으로 정지규칙으로 사용된다.
```{r ex_3_2}
net.sqrt <- neuralnet(Output~Input,train.data, hidden=10, threshold=0.01)
print(net.sqrt)
```


적합된 신경망모형은 plot() 함수를 통해 다음과 같이 시각화 된다.
```{r ex_3_3}
plot(net.sqrt)
```


몇 개의 검증용 자료에 대해 구축된 신경망 모형을 적용한다.  
1~10 정수값의 제곱을 취하여 검증용 자료(test.data)를 만든 후,  
이 자료에 대해 compute() 함수를 통해 신경망 모형 (net.sqrt)을 적용하고,  
그 결과를 출력한다.
```{r ex_3_4}
test.data <- as.data.frame((1:10)^2)
test.out <- compute(net.sqrt, test.data)
ls(test.out)
```



```{r ex_3_5}
 print(test.out$net.result)
```


이제 은닉층이 2개인 모형을 적합해 보자.  
각각의 은닉 노드의 수는 10개, 8개로 한다. 이를 위해 neuralnet() 함수의 옵션을 hidden=c(10,8)으로 수정하여 위 과정을 실행한다.   
그 결과는 다음과 같다.
```{r ex_3_6}
net2.sqrt <- neuralnet(Output~Input,train.data, hidden=c(10,8), threshold=0.01)
plot(net2.sqrt)
```
```{r ex_3_7}
test2.out <- compute(net2.sqrt, test.data)
print(test2.out$net.result)
```
