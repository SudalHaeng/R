---
title: "DataMining_7"
author: "Lee Jun Haeng"
date: '2021 11 10 '
output: html_document
---

# k-인접이웃분류(knn)

### 예제1
자료 iris3을 이용하여 분석을 수행한다.  
R 패키지 {class}의 knn() 함수를 이용하여 k-NN 분류를 수행한다.  
```{r knn1}

library(class)
data(iris3)  # 3차원 배열 자료 (50 x 4 x 3)
train <- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])  # 행렬 객체임
test <- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)))
knn(train, test, cl, k=3, prob=TRUE)
```


### 예제2
iris 자료를 이용하여 k-NN 분류분석을 수행한다.
R 패키지 {DMwR}의 kNN() 함수를 이용하여 k-근접이웃분류를 수행한다.  
kNN() 함수는 knn{class} 함수와 유사하나, 모형식 기반으로 수행되는 차이점이 있으며 자료에 대한 정규화 옵션(norm= )을 제공한다.  
```{r knn2}
data(iris)
idxs <- sample(1:nrow(iris), as.integer(0.7*nrow(iris)))
trainIris <- iris[idxs,]
testIris <- iris[-idxs,]
```

DMwR 패키지가 R 에서 삭제됨  
kNN() 함수를 통해 k=3인 인접이웃분류를 수행한 결과는 다음과 같다.   norm=FALSE 옵션은 자료에 대한 정규화를 수행하지 않고 분석을 수행한다.  
디폴트는 TRUE 이다.
```{r knn2_1}
#install.packages("DMwR")
#library(dmwr)
# nn3 <- kNN(Species ~ ., trainIris, testIris, norm=FALSE, k=3)
# table(testIris[,'Species'], nn3)
```
norm=TRUE 옵션은 자료에 대한 정규화를 수행하고 분석을 수행
```{r knn2_2}
# nn5 <- kNN(Species ~ ., trainIris, testIris, norm=FALSE, k=5)

```

### 예제3
iris 자료를 이용하여 k-NN 분류분석을 수행한다.  
R 패키지 {kknn}의 kknn() 함수를 이용하여 k-근접이웃분류를 수행한다.  
kknn() 함수는 가중(weighted) k-NN 분류를 제공한다.  
```{r knn3}
library(kknn)
data(iris)
m <- dim(iris)[1]
val <- sample(1:m, size=round(m/3), replace=FALSE,
              prob=rep(1/m, m))
iris.learn <- iris[-val,]
iris.valid <- iris[val,]
```
kknn() 함수를 이용하여 k-NN 분류 분석을 수행한다. knnn() 함수는 검증용 저료의 각 열에 대해 k-인접이웃을 민코우스키 거리에 기반하여 구한다.  


```{r knn3_1}
 iris.kknn <- kknn(Species~., iris.learn, iris.valid, distance=1,
kernel="triangular")
summary(iris.kknn)
```
distance= 옵션은 민코우스키 거리의 모수(parameter)를 지정하며, distance=2 는 유클리드거리에 해당한다.  
kernel= 옵션은 이웃점들의 가중치를 부여하는 방법을 지정한다.  
kernel= 옵션에는 "rectangular"(이는 가중을 고려하지 않은 표준 k-NN과 동일),
"triangular", "epanechnikov"(또는 beta(2,2)), "biweight"(또는 beta(3,3)), "triweight" (또는 beta(4,4)), "cos", "inv", "gaussian", "rank" 와 "optimal"이 있다.  
가중 k-NN 분류는 커널밀도함수의 합이 최대인 군집으로 분류를 수행한다.  

```{r knn3_2}
fit <- fitted(iris.kknn)
table(iris.valid$Species, fit)
```

```{r knn3_3}
pcol <- as.character(as.numeric(iris.valid$Species))
pairs(iris.valid[1:4], pch=pcol,
col=c("green3", "red")[(iris.valid$Species != fit)+1])

```


### 예제4
미 프로야구 선수 6명에 대해 두 시즌간의 기록(lag1, lag2)이 다음 해의 득점(runs)에 미친 영향을 알아보기 위해 k-NN 회귀를 수행하였다.  
  
k-NN 알고리즘의 수행 결과로부터 검증용 데이터에 가장 가까운 k 개의 자료를 구체적으로 구하는 두 가지 방법을 알려준다.  
이 가운데 한 가지는 R 패키지 {FNN}을 이용한다.  
{FNN}은 Fast Nearest Neighbor Search Algorithms and Applications을
의미한다.

```{r knn4}
full <- data.frame(name=c("McGwire,Mark", "Bonds,Barry",
"Helton,Todd", "Walker,Larry",
"Pujols,Albert", "Pedroia,Dustin"),
lag1 = c(100,90,75,89,95,70),
lag2 = c(120,80,95,79,92,90),
Runs = c(65,120,105,99,65,100))
full
```

R 패키지 {kknn}의 kknn() 함수를 통해 k-NN 회귀를 수행하였다.  
5명의 선수 자료를 훈련용으로하고, 한 명의 선수("Bonds,Barry")를 검증용으로 하여 예측을 수행하였다.  

```{r knn4_1}
library(kknn)
train <- full[full$name!="Bonds,Barry",]
test <- full[full$name=="Bonds,Barry",]
k <- kknn(Runs~lag1+lag2, train=train, test=test, k=2, distance=1)
fit <- fitted(k)
fit
```
Bonds의 예측결과로 90.5를 얻었다.  
이 결과는 아래의 k$fitted.values를 통해서도 확인할 수 있다

```{r knn4_2}
names(k)
k$fitted.values
```
위 결과에서 CL은 k-근접이웃의 class의 행렬, W는 k-근접이웃의 가중치의 행렬, D는 k-근접 이웃의 거리행렬, C는 k-근접이웃의 위치(indices) 등을 나타낸다.  

```{r knn4_3}
k$CL
k$W
```
위 결과로부터 Bonds와 가장 가까운 2개의 인접값(득점)으로 99와 65를 얻었다.  
두 값의 가중치는 각각 0.75와 0.25이며, Bonds의 예측치 90.5는 가중평균((99*3+65)/4=90.5)으로부터 구해진 값이다.  


이 과정에서 두 개의 인접값 중 99는 한명의 선수에만 해당되지만, 65는 두 명의 선수
(McGwire와 Pujols)가 이 값을 가진다.  
만약 Bonds의 인접이웃이 누구인지를 정확히 알고 싶다면 다음과 같이 수행하면 될 것이다.  
```{r knn4_4}
k$C
train[c(k$C),]
```

위의 결과는 인접이웃의 위치가 훈련용 자료에서 3, 4번째임을 알려주며, 이를 출력하면
Walker와 Pujols가 Bonds의 인접이웃임을 알 수 있다.  


R의 {FNN} 패키지는 훈련용 자료에 대해 원하는 질의(query)를 통해 필요한 결과를 얻게 해준다.  
다음은 get.knnx() 함수를 통해 인접이웃을 구하는 과정을 보여준다.  

```{r knn4_5}
library(FNN)
get.knnx(data=train[,c("lag1","lag2")],
query=test[,c("lag1","lag2")], k=2)
 train[c(3,4), "name"] # 훈련용 자료에서 3, 4번의 이름
```
따라서 Bonds와 가까운 인접이웃은 Walker와 Pujols이다.  
위 결과에서 인접이웃과의 거리($nn.dist)는 디폴트로 유클리드거리가 제공되었다.




### {caret}을 이용한 k-NN 분석  
R 패키지 {caret}을 이용하여 k-NN 분석을 수행한다.  

##### (a) 표본추출
```{r knn_caret_a}
library(ISLR)
library(caret)
```
{caret} 패키지의 createDataPartition() 함수를 이용하여 훈련용 자료와 검증용 자료로
나눈다.  
```{r knn_caret_a_2}
set.seed(100)
indxTrain <- createDataPartition(y = Smarket$Direction, p = 0.75,
                                 list = FALSE)
training <- Smarket[indxTrain,]
testing <- Smarket[-indxTrain,]
```

원 자료와 분할된 자료의 분포를 비교한다.  
```{r knn_caret_a_3}
prop.table(table(training$Direction)) * 100
prop.table(table(testing$Direction)) * 100
prop.table(table(Smarket$Direction)) * 100
```
createDataParition()은, 자료 분할을 위해 이전에 사용되었던 방식보다, 매우 편리하게 자료를 분할함을 알 수 있다.  

##### (b) 전처리  
k-NN 분류를 수행하기 위해서는 변수의 정규화 또는 척도화가 필요하다.  
{caret}은 데이터 전처리를 위한 도구를 제공한다.  
preProcess() 함수를 통해 변수에 대한 중심화와 척도화를 수행한다.  
```{r knn_caret_b}
trainX <- training[,names(training) != "Direction"] # 반응변수를 제외
preProcValues <- preProcess(x = trainX,
method = c("center", "scale"))
preProcValues
```

##### (c) 훈련과 훈련 조절
```{r knn_caret_c}
set.seed(200)
ctrl <- trainControl(method="repeatedcv", repeats = 3)
# 추가 가능 옵션: classProbs=TRUE,summaryFunction = twoClassSummary
knnFit <- train(Direction ~ ., data = training, method = "knn",
trControl = ctrl,
preProcess = c("center","scale"), tuneLength = 20)
# k-NN 적합 결과
knnFit
```

인접이웃(k)의 크기에 따라, 교차타당법에 기초하여, 정확도를 구하면 다음과 같다  
```{r knn_caret_c_1}
plot(knnFit)
```
[해석]  
인접 이웃의 크기(k)가 25일 때, 정확도가 제일 높다.  
훈련용 자료에 대해 적합된 최적 모형은 자동으로 이 값을 선택한다.  
  
  
적합된 모형을 이용하여 검증용 자료에 대해 예측을 수행하면 다음과 같다  
```{r knn_caret_c_2}
knnPredict <- predict(knnFit, newdata = testing )
confusionMatrix(knnPredict, testing$Direction )
```

```{r knn_caret_c_3}
mean(knnPredict == testing$Direction)
```
[해석]  
검증용 자료에 대한 정확도가 90.7%로 나타났다.  
훈련용 자료보다도 더 높게 나타나, 과적합의 문제는 없는 것으로 판단된다.  
  
  
  
summary=twoClassSummary를 지정하면 두 집단 문제에서 AUC, 민감도, 특이도 등의
성능 측도를 제공한다.  
classProbs=TRUE는 이러한 측도의 계산에 필요하다.  
tuneLength=20은 조절모수의 격자를 조절하는 값이다.  

```{r knn_caret_c_4}
# 2 클래스 요약함수 확인
set.seed(200)
ctrl <- trainControl(method="repeatedcv",
                     repeats = 3,
                     classProbs=TRUE,
                     summaryFunction = twoClassSummary)
knnFit <- train(Direction ~ ., data = training,
                method = "knn", 
                trControl = ctrl,
                preProcess = c("center","scale"), 
                tuneLength = 20)
# k-NN 적합 결과
knnFit
```



```{r knn_caret_c_5}
# 이웃의 수에 대한 정확도 그림(반복된 교차타당법에 의한)
plot(knnFit, print.thres = 0.5, type="S")
```
적합모형은 인접이웃으로 k=43을 선택하였다(AUC 기준 사용).   
k=25도 훌륭한 대안으로생각된다  
(이 값은 앞서 정확도 기준을 적용한 결과와 동일함).


적합된 모형을 이용하여 검증용 자료에 대해 예측을 수행하면 다음과 같다.  
정분류율 관점에서 모형의 성능이 다소간 향상되었음을 확인할 수 있다  
(90.7% -> 91.7%).
```{r knn_caret_c_6}
# 검증용 자료에 대한 예측
knnPredict <- predict(knnFit, newdata = testing )
confusionMatrix(knnPredict, testing$Direction ) # 정오분류행렬
```
```{r knn_caret_c_7}
mean(knnPredict == testing$Direction)
```

```{r knn_caret_c_8}
# ROC 곡선 그리기
library(pROC)
knnPredict <- predict(knnFit, newdata = testing , type="prob")
knnPredict
knnROC <- roc(testing$Direction, knnPredict[,"Down"],
levels = levels(testing$Direction))
# 밑줄 부분 출력: [1] “Down” “Up” (문자형 벡터)
knnROC
plot(knnROC, type="S", print.thres= 0.5) # 기준값 0.5일 때의 결과를 표시
```


##### (d) 랜덤포리스트(method=“rf”)를 적용한 결과
랜덤포리스트 방법을 적용하여 모형을 구축하고, 앞서 다룬 k-NN 방법과의 성능을 비교한다.  

랜덤포리스트는 일종의 앙상블 모형으로, 대체로 성능이 매우 뛰어난 방법으로 알려져 있다.  


```{r knn_caret_d}
set.seed(300)
ctrl <- trainControl(method="repeatedcv", repeats = 3)
# 추가 가능 옵션: classProbs=TRUE, summaryFunction =
twoClassSummary
```




```{r knn_caret_d_1}
# 랜덤포리스트
rfFit <- train(Direction ~ ., data = training,
                 method = "rf",
                 trControl = ctrl,
                 preProcess = c("center","scale"),
                 tuneLength = 20)
rfFit
```

```{r knn_caret_d_2}
plot(rfFit)
```


적합된 모형을 이용하여 검증용 자료에 대해 예측을 수행하면 다음과 같다.  
랜덤포리스트 모형이 검증용 자료를 완벽하게 분류함을 확인할 수 있다  
(정분류율=100%).
```{r knn_caret_d_3}
rfPredict <- predict(rfFit, newdata = testing )
confusionMatrix(rfPredict, testing$Direction )
```

```{r knn_caret_d_4}
mean(rfPredict == testing$Direction)
```
[해석]  
정확도 기준에 의해, 구축된 랜덤포리스트 모형의 성능이 매우 우수함을 알 수 있다.  

  
  
두 집단 요약(summaryFunction=twoClassSummary) 옵션을 사용하여, AUC 기준에 의한
랜덤포리스트 모형을 구축하였다.  

```{r knn_caret_d_5}
# 2 클래스 요약함수 사용
set.seed(300)
ctrl <- trainControl(method="repeatedcv", repeats = 3,
classProbs=TRUE, summaryFunction=twoClassSummary)
rfFit <- train(Direction ~ ., data = training, method = "rf",
trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
rfFit
```
```{r knn_caret_d_6}
plot(rfFit)
```


```{r knn_caret_d_7}
# 몇 가지 매개변수로 플롯하기
plot(rfFit, print.thres = 0.5, type="S")
```
```{r knn_caret_d_8}
rfPredict <- predict(rfFit, newdata = testing )
confusionMatrix(rfPredict, testing$Direction )


```

```{r knn_caret_d_9}
mean(rfPredict == testing$Direction)

```
[해석]  
AUC 기준에 의해, 구축된 랜덤포리스트 모형의 성능이 매우 우수함을 알 수 있다  
(정확도 기준에 의한 결과와 동일).  



```{r knn_caret_d_10}
# ROC 곡선 그리기
rfPredict <- predict(rfFit,newdata = testing , type="prob")
rfROC <- roc(testing$Direction, rfPredict[,"Down"],
             levels = rev(testing$Direction))
rfROC
```
```{r knn_caret_d_11}
plot(rfROC, type="S", print.thres= 0.5)
```
[해석]  
AUC 기준에 의해, 구축된 랜덤포리스트 모형의 성능이 매우 우수함을 알 수 있다  
(정확도 기준에 의한 결과와 동일).

